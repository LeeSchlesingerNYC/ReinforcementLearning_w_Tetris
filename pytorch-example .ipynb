{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pygame\n",
    "from datetime import datetime\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "# from tf_agents.environments import tf_environment\n",
    "# from tf_agents.environments import tf_py_environment\n",
    "# from tf_agents.environments import utils\n",
    "# from tf_agents.specs import array_spec\n",
    "# from tf_agents.environments import wrappers\n",
    "# from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "# tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "# from simple_dqn_torch_2020 import Agent\n",
    "# from utils import plotLearning\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up game area layout\n",
    "# By changing the block_size other aspects will scale\n",
    "block_size = 30    # Size of side of square\n",
    "blocks_w = 10      # game width (in blocks)\n",
    "blocks_h = 20      # game height (in blocks)\n",
    "border_w = 500\n",
    "border_h = 100\n",
    "end_wait = 2000\n",
    "\n",
    "play_w = blocks_w * block_size  # Width is 10 blocks\n",
    "play_h = blocks_h * block_size  # Height is 20 blocks\n",
    "full_w = 2 * border_w + play_w\n",
    "full_h = 2 * border_h + play_h + 50\n",
    "top_left_x = border_w\n",
    "top_left_y = 2 * border_h\n",
    "start_x = int(blocks_w / 2)\n",
    "\n",
    "NO_KEY = 0\n",
    "LEFT_KEY = 1\n",
    "RIGHT_KEY = 2\n",
    "DOWN_KEY = 3\n",
    "UP_KEY = 4\n",
    "\n",
    "\n",
    "I = [['..0..',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '0000.',\n",
    "      '.....',\n",
    "      '.....',\n",
    "      '.....']]\n",
    "#J\n",
    "J = [['.....',\n",
    "      '.0...',\n",
    "      '.000.',\n",
    "      '.....',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..00.',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '.....',\n",
    "      '.000.',\n",
    "      '...0.',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '.00..',\n",
    "      '.....']]\n",
    "#L\n",
    "L = [['.....',\n",
    "      '.....',\n",
    "      '.000.',\n",
    "      '.0...',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '.00..',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '...0.',\n",
    "      '.000.',\n",
    "      '.....',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '..00.',\n",
    "      '.....']]\n",
    "#O\n",
    "O = [['.....',\n",
    "      '.....',\n",
    "      '.00..',\n",
    "      '.00..',\n",
    "      '.....']]\n",
    "#S\n",
    "S = [['.....',\n",
    "      '..0..',\n",
    "      '..00.',\n",
    "      '...0.',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '.....',\n",
    "      '..00.',\n",
    "      '.00..',\n",
    "      '.....']]\n",
    "#T\n",
    "T = [['.....',\n",
    "      '..0..',\n",
    "      '.000.',\n",
    "      '.....',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '..00.',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '.....',\n",
    "      '.000.',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '.00..',\n",
    "      '..0..',\n",
    "      '.....']]\n",
    "#Z\n",
    "Z = [['.....',\n",
    "      '.....',\n",
    "      '.00..',\n",
    "      '..00.',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '.00..',\n",
    "      '.0...',\n",
    "      '.....']]\n",
    "shapes = [I, J, L, O, S, T, Z]\n",
    "shapes_color = [(255,0,0),(0,255,0),\n",
    "                (0,0,255),(0,255,255),\n",
    "                (255,0,255),(255,255,0),\n",
    "                (128,0,128)]\n",
    "pygame.font.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Piece(object):\n",
    "    def __init__ (self, x, y, shape):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.shape = shape\n",
    "        self.color = shapes_color[shapes.index(shape)]\n",
    "        self.rotation = int(np.random.rand()*len(shape))\n",
    "\n",
    "def create_grid(locked_pos = {}):\n",
    "    grid = [[(0,0,0) for _ in range(blocks_w)] for _ in range(blocks_h)]\n",
    "    for hgt in range(blocks_h):\n",
    "        for wid in range(blocks_w):\n",
    "            if (wid, hgt) in locked_pos:\n",
    "                clr = locked_pos[(wid,hgt)]\n",
    "                grid[hgt][wid] = clr\n",
    "    return grid\n",
    "\n",
    "def convert_shape_fmt(this_shape):\n",
    "    posit = []\n",
    "    fmt = this_shape.shape [this_shape.rotation % len(this_shape.shape)]\n",
    "    for i, line in enumerate(fmt):\n",
    "        row = list(line)\n",
    "        for j, col in enumerate(row):\n",
    "            if col == '0':\n",
    "                posit.append((int(this_shape.x + j), int(this_shape.y + i)))\n",
    "                             \n",
    "    for i, pos in enumerate(posit):\n",
    "        posit[i] = (int(pos[0]-2), int(pos[1]-4))\n",
    "    return posit\n",
    "\n",
    "def valid_space(grid, piece):\n",
    "    accepted_pos = [[(j,i) for j in range (blocks_w) if grid[i][j] == (0,0,0)] for i in range (blocks_h)]\n",
    "    accepted_pos = [j for sub in accepted_pos for j in sub]\n",
    "    formatted = convert_shape_fmt(piece)\n",
    "    for pos in formatted:\n",
    "        if pos not in accepted_pos:\n",
    "            if pos[1] > -1:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def check_lost(positions):\n",
    "    for pos in positions:\n",
    "        x, y = pos\n",
    "        if y < -1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_shape():\n",
    "    return Piece(start_x, 0, np.random.choice(shapes))\n",
    "\n",
    "def draw_text_middle(surface, text, size, color):\n",
    "    font = pygame.font.SysFont('Arial',size, bold = True)\n",
    "    bolded = font.render(text, 1, color)\n",
    "    surface.blit(bolded,((full_w-bolded.get_width())/2, (full_h-bolded.get_height())/2))\n",
    "\n",
    "def draw_grid(surface, grid):\n",
    "    for hgt in range(blocks_h+1):\n",
    "        pygame.draw.line(surface,(128,128,128), \n",
    "                         (top_left_x, top_left_y + hgt*block_size), \n",
    "                         (top_left_x + blocks_w*block_size, top_left_y + hgt*block_size))\n",
    "    for wid in range(blocks_w+1):\n",
    "        pygame.draw.line(surface,(128,128,128), \n",
    "                         (top_left_x + wid*block_size, top_left_y), \n",
    "                         (top_left_x + wid*block_size, top_left_y + blocks_h*block_size))\n",
    "\n",
    "\n",
    "def clear_rows(grid, locked):\n",
    "\n",
    "    inc = 0\n",
    "    # backward (bottom to top scan)\n",
    "    for i in range(len(grid)-1, -1, -1):\n",
    "        row = grid[i]\n",
    "        if (0, 0, 0) not in row:\n",
    "            inc += 1\n",
    "            for j in range(len(row)):\n",
    "                del locked[(j,i)]\n",
    "        else:\n",
    "            if inc > 0:\n",
    "                k = i+inc\n",
    "                for j in range(len(row)):\n",
    "                    if (j,i) in locked:\n",
    "                        locked[(j,k)] = locked[(j,i)]\n",
    "                        del locked[(j,i)]\n",
    "\n",
    "    return inc, locked\n",
    "\n",
    "def draw_next_shape(surface, shp):\n",
    "    font = pygame.font.SysFont('Arial',60)\n",
    "    next_s = font.render('Next Shape:',1, (255,255,255))\n",
    "    next_x = top_left_x + play_w + 150\n",
    "    next_y = top_left_y + play_h/2 - 150\n",
    "    fmt = shp.shape[shp.rotation]\n",
    "    \n",
    "    for i, line in enumerate(fmt):\n",
    "        row = list(line)\n",
    "        for j,col in enumerate(row):\n",
    "            if col == '0':\n",
    "                pygame.draw.rect(surface, shp.color, (next_x + j*block_size, \n",
    "                                 next_y + i*block_size, \n",
    "                                 block_size, block_size), 0)\n",
    "    surface.blit(next_s, (next_x - 50, next_y - 100))\n",
    "\n",
    "def add_score(score):\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\\n\")\n",
    "    with open('data/score_log','a') as f:\n",
    "        f.writelines(str(int(score))+','+dt_string)\n",
    "    return score\n",
    "\n",
    "def draw_window(surface, grid, score):\n",
    "    surface.fill((0,0,0))\n",
    "    pygame.font.init()\n",
    "    font = pygame.font.SysFont('Arial',60)\n",
    "    title = font.render('Tetris',1, (255,255,255))\n",
    "    surface.blit(title,(full_w/2 - title.get_width()/2, 20))\n",
    "    \n",
    "    font = pygame.font.SysFont('Arial',60)\n",
    "    score_s = font.render('Score:',1, (255,255,255))\n",
    "    score_x = 50\n",
    "    score_y = top_left_y + 50\n",
    "    surface.blit(score_s, (score_x, score_y))\n",
    "    score_s = font.render(str(score),1, (255,255,255))\n",
    "    score_x = 100\n",
    "    score_y += 100\n",
    "    surface.blit(score_s, (score_x, score_y))\n",
    "    \n",
    "    for hgt in range(blocks_h):\n",
    "        for wid in range(blocks_w):\n",
    "            pygame.draw.rect(surface, grid[hgt][wid],\n",
    "                             (top_left_x + wid*block_size, \n",
    "                            top_left_y + hgt*block_size, \n",
    "                            block_size, block_size), 0)\n",
    "    pygame.draw.rect(surface, (255,0,0), (top_left_x, top_left_y, play_w, play_h), 4)\n",
    "    draw_grid(surface, grid)\n",
    "#     pygame.display.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tetris(py_environment.PyEnvironment):\n",
    "\n",
    "    def __init__(self):\n",
    "#         self._action_spec = array_spec.BoundedArraySpec(\n",
    "#             shape=(), dtype=np.int32, minimum=0, maximum=4, name='action')\n",
    "#         self._observation_spec = array_spec.BoundedArraySpec(\n",
    "#             shape=(blocks_h,blocks_w), dtype=np.int32, minimum=0, name='observation')\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        self.win = pygame.display.set_mode((full_w, full_h))\n",
    "        pygame.display.set_caption('Tetris')\n",
    "        self.win.fill((0, 0, 0))\n",
    "#         draw_text_middle(win,\"Press any key to Start\", 60, (255, 255, 255))\n",
    "        self.locked_blocks = {}\n",
    "        self.grid = create_grid(self.locked_blocks)\n",
    "\n",
    "        self.change_piece = False\n",
    "#     run = True\n",
    "        self.next_piece = get_shape()\n",
    "        self.curr_piece = get_shape()\n",
    "        self.score = 0\n",
    "        self.lost = False\n",
    "        pygame.display.update()\n",
    "    \n",
    "#     clock = pygame.time.Clock()\n",
    "#     fall_time = 0\n",
    "#     fall_speed =.27\n",
    "#     level_time = 0\n",
    "#     score = 0\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self.grid\n",
    "#         return self._observation_spec\n",
    "\n",
    "    def time_step_spec(self):\n",
    "        \"\"\"Return time_step_spec.\"\"\"\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "#     if self._episode_ended:\n",
    "#       # The last action ended the episode. Ignore the current action and start\n",
    "#       # a new episode.\n",
    "#       TETRIS BOARD CLOGGED\n",
    "#       return self.reset()\n",
    "\n",
    "#     # Make sure episodes don't go on forever.     \n",
    "#     TETRIS GAME WILL END\n",
    "#     if action == 1:\n",
    "#       self._episode_ended = True\n",
    "#     elif action == 0:\n",
    "#       new_card = np.random.randint(1, 11)\n",
    "#       self._state += new_card\n",
    "#     else:\n",
    "        if action < 0 or action > 4:\n",
    "            raise ValueError('`action` should be between 0 and 4.')\n",
    "        self.curr_piece.y += 1\n",
    "        self.grid = create_grid(self.locked_blocks)\n",
    "        if not (valid_space(self.grid, self.curr_piece)) and (self.curr_piece.y > 0):\n",
    "            self.curr_piece.y -= 1\n",
    "            self.change_piece = True\n",
    "        \n",
    "        self.grid = create_grid(self.locked_blocks)\n",
    "        key_choice = action #(self.grid, self.curr_piece)\n",
    "        if key_choice == LEFT_KEY:\n",
    "            self.curr_piece.x -= 1\n",
    "            if not (valid_space(self.grid, self.curr_piece)):\n",
    "                self.curr_piece.x += 1\n",
    "        if key_choice == RIGHT_KEY:\n",
    "            self.curr_piece.x += 1\n",
    "            if not (valid_space(self.grid, self.curr_piece)):\n",
    "                self.curr_piece.x -= 1\n",
    "        if key_choice == DOWN_KEY:\n",
    "            while valid_space(self.grid, self.curr_piece):\n",
    "                self.curr_piece.y += 1\n",
    "            self.curr_piece.y -= 1\n",
    "        if key_choice == UP_KEY:\n",
    "            self.curr_piece.rotation += 1 \n",
    "            self.curr_piece.rotation %= len(self.curr_piece.shape)\n",
    "            if not (valid_space(self.grid, self.curr_piece)):\n",
    "                if self.curr_piece.rotation == 0:\n",
    "                    self.curr_piece.rotation = len(self.curr_piece.shape) - 1\n",
    "                else:\n",
    "                    self.curr_piece.rotation -= 1\n",
    "        # if none of the above, piece drops one row\n",
    "\n",
    "        shape_pos = convert_shape_fmt(self.curr_piece)\n",
    "        for i in range(len(shape_pos)):\n",
    "            x, y = shape_pos[i]\n",
    "            if y > -1:\n",
    "                self.grid[y][x] = self.curr_piece.color\n",
    "        if self.change_piece:\n",
    "            for pos in shape_pos:\n",
    "                p = (pos[0],pos[1])\n",
    "                self.locked_blocks[p] = self.curr_piece.color\n",
    "            self.curr_piece = self.next_piece\n",
    "            self.next_piece = get_shape()\n",
    "            self.change_piece = False\n",
    "            increment, new_block_set = clear_rows(self.grid, self.locked_blocks)\n",
    "            self.score += increment * 10\n",
    "            self.locked_blocks = new_block_set\n",
    "\n",
    "        draw_window(self.win, self.grid, self.score)\n",
    "        draw_next_shape(self.win, self.next_piece)\n",
    "        pygame.display.update()\n",
    "\n",
    "        self._state = 1\n",
    "        if check_lost(self.locked_blocks):\n",
    "#             draw_text_middle(win, \"You Lost!\", 80, (255, 255, 255))\n",
    "            self._state = 2\n",
    "            self.lost = True\n",
    "            pygame.display.update()\n",
    "#             pygame.time.delay(end_wait)\n",
    "#             run = False\n",
    "            self.score = add_score(self.score)\n",
    "            self._episode_ended = True\n",
    "        if self._episode_ended:\n",
    "            return ts.termination(np.array([self._state], dtype=np.int32), self.score)\n",
    "        else:\n",
    "            return ts.transition(\n",
    "                np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)\n",
    "#     return win, score, grid, locked_blocks, curr_piece, next_piece, check_lost\n",
    "#     if self._episode_ended or self._state >= 21:\n",
    "#       reward = self._state - 21 if self._state <= 21 else -21\n",
    "#       return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "#     else:\n",
    "#       return ts.transition(\n",
    "#           np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep(step_type=array(2, dtype=int32), reward=array(0., dtype=float32), discount=array(0., dtype=float32), observation=array([2], dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(0., dtype=float32), discount=array(0., dtype=float32), observation=array([2], dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(0., dtype=float32), discount=array(0., dtype=float32), observation=array([2], dtype=int32))\n",
      "Final Reward =  0.0\n"
     ]
    }
   ],
   "source": [
    "environment= Tetris()\n",
    "get_new_card_action = np.array(0, dtype=np.int32)\n",
    "end_round_action = np.array(2, dtype=np.int32)\n",
    "\n",
    "# environment = Tetris()\n",
    "time_step = environment.reset()\n",
    "# print(time_step)\n",
    "cumulative_reward = time_step.reward\n",
    "\n",
    "for episode in range (3):\n",
    "    time_step = environment.reset()\n",
    "    done = False\n",
    "    # for _ in range(20):\n",
    "    while not done:\n",
    "        time_step = environment.step(get_new_card_action)\n",
    "        #     print(time_step)\n",
    "        cumulative_reward += time_step.reward\n",
    "        if time_step.step_type == 2:\n",
    "            print(time_step)\n",
    "            done = True\n",
    "            time_step = environment.step(end_round_action)\n",
    "            \n",
    "            now = datetime.now()\n",
    "            dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\\n\")\n",
    "            with open('data/score_log','a') as f:\n",
    "                f.writelines(str(episode+1)+','+str(int(time_step.reward))+','+dt_string)\n",
    "#         return score\n",
    "\n",
    "\n",
    "#comment out the following line to display last result\n",
    "pygame.display.quit()\n",
    "\n",
    "# print(time_step)\n",
    "cumulative_reward += time_step.reward\n",
    "print('Final Reward = ', cumulative_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__ (self, lr, input_dims, fc1_dims, fc2_dims, n_actions):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc3 = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.loss = nn.MSELoss()\n",
    "#         self.device = T.device('cuda:0' if T.cuda.is_available else 'cpu')\n",
    "        self.device = 'cpu'\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        actions = F.relu(self.fc3(x))\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__ (self, gamma, epsilon, lr, input_dims, batch_size, n_actions, \n",
    "                  max_mem_size=100000, eps_end = .01, eps_dec=5e-4):\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.eps_end = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "        self.action_space = [i for i in range (n_actions)]\n",
    "        self.mem_size = max_mem_size\n",
    "        self.mem_cntr = 0\n",
    "        \n",
    "        self.Q_eval = DeepQNetwork(self.lr, n_actions = n_actions, input_dims = input_dims,\n",
    "                                  fc1_dims=256, fc2_dims=256)\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "        \n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        indx = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[indx] = state\n",
    "        self.new_state_memory[indx] = state_\n",
    "        self.action_memory[indx] = action\n",
    "        self.reward_memory[indx] = reward\n",
    "        self.terminal_memory[indx] = done\n",
    "        self.mem_cntr += 1\n",
    "        \n",
    "    def choose_action(self, observation):\n",
    "        if np.random.random() > self.epsilon:\n",
    "            state = T.tensor([observation]).to(self.Q_eval.device)\n",
    "            actions = self.Q_eval_forward(state)\n",
    "            action = T.argmax(actions).item()\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        return action\n",
    "    \n",
    "    def learn(self):\n",
    "        if self.mem_cntr < self.batch_size:\n",
    "            return\n",
    "        self.Q_eval.optimizer.zero_grad()\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, self.batch_size, replace = False)\n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        print(batch)\n",
    "        print (self.new_state_memory[batch])\n",
    "        state_batch = T.tensor(self.state_memory[batch]).to(self.Q_eval.device)\n",
    "        new_state_batch = T.tensor(self.new_state_memory[batch]).to(self.Q_eval.device)\n",
    "        reward_batch = T.tensor(self.reward_memory[batch]).to(self.Q_eval.device)\n",
    "        terminal_batch = T.tensor(self.terminal_memory[batch]).to(self.Q_eval.device)\n",
    "        action_batch = self.action_memory[batch]\n",
    "        q_eval = self.Q_eval.forward(state_batch)[batch_index, action_batch]\n",
    "        q_next = self.Q_eval.forward(new_state_batch)\n",
    "        q_next[terminal_batch] = 0.0\n",
    "        q_target = reward_batch + self.gamma * T.max(q_next, dim=1)[0]\n",
    "        loss = self.Q_eval.loss(q_target, q_eval).to(self.Q_eval.device)\n",
    "        loss.backward()\n",
    "        self.Q_eval.optimizer.step()\n",
    "        self.epsilon = self.epsilon - self.eps_dec if self.epsilon>self.eps_min else self.eps_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 44 21  9 27 22 23 33 39 17 37 47  1 15 18 48  7 35 25 12 10 36  4 34\n",
      " 40  0 30  3 43 49 45 29 38  5  2 32 46 20 28 19 42 41 14 16 24 26 31  8\n",
      " 13 11]\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7df5d42d1974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ff3baffdaa50>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_state_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mstate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mnew_state_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_state_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mreward_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = Tetris()\n",
    "#     agent = Agent(gamma =.99, epsilon = 1.0, batch_size=50, n_actions=5, eps_end = .01, \n",
    "# input_dims=[blocks_w][blocks_h], lr =.003)\n",
    "#     agent = Agent(gamma =.99, epsilon = 1.0, batch_size=50, n_actions=5, eps_end = .01, \\\n",
    "#                   input_dims=[200], lr =.003)\n",
    "    agent = Agent(gamma =.99, epsilon = 1.0, batch_size=50, n_actions=5, eps_end = .01, \\\n",
    "                  input_dims=[4], lr =.003)\n",
    "    scores, eps_history = [], []\n",
    "    n_games = 500\n",
    "    \n",
    "    for i in range (n_games):\n",
    "        score = 0\n",
    "        done = env.lost\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score = reward\n",
    "            agent.store_transition(observation, action, reward, observation_, done)\n",
    "            agent.learn()\n",
    "            observation = observation_\n",
    "            done = env.lost\n",
    "        scores.append(score)\n",
    "        eps_history.append(agent.epsilon)\n",
    "        avg_score = np.mean(scores[-100:])\n",
    "        \n",
    "        print('episode', i, 'score %.2f' % score,\n",
    "             'average score %.2f' % avg_score,\n",
    "             'epsilon %.2f' % agent.epsilon)\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    filename = 'data/pytouch_img.png'\n",
    "    plot_learning_curve(x, scores, eps_history, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.display.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
