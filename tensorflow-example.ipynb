{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "# import pyvirtualdisplay\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pygame\n",
    "from datetime import datetime\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow hyperparameters\n",
    "\n",
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up game area layout\n",
    "# By changing the block_size other aspects will scale\n",
    "block_size = 30    # Size of side of square\n",
    "blocks_w = 10      # game width (in blocks)\n",
    "blocks_h = 20      # game height (in blocks)\n",
    "border_w = 500\n",
    "border_h = 100\n",
    "end_wait = 2000\n",
    "\n",
    "play_w = blocks_w * block_size  # Width is 10 blocks\n",
    "play_h = blocks_h * block_size  # Height is 20 blocks\n",
    "full_w = 2 * border_w + play_w\n",
    "full_h = 2 * border_h + play_h + 50\n",
    "top_left_x = border_w\n",
    "top_left_y = 2 * border_h\n",
    "start_x = int(blocks_w / 2)\n",
    "\n",
    "NO_KEY = 0\n",
    "LEFT_KEY = 1\n",
    "RIGHT_KEY = 2\n",
    "DOWN_KEY = 3\n",
    "UP_KEY = 4\n",
    "\n",
    "\n",
    "I = [['..0..',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '0000.',\n",
    "      '.....',\n",
    "      '.....',\n",
    "      '.....']]\n",
    "#J\n",
    "J = [['.....',\n",
    "      '.0...',\n",
    "      '.000.',\n",
    "      '.....',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..00.',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '.....',\n",
    "      '.000.',\n",
    "      '...0.',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '.00..',\n",
    "      '.....']]\n",
    "#L\n",
    "L = [['.....',\n",
    "      '.....',\n",
    "      '.000.',\n",
    "      '.0...',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '.00..',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '...0.',\n",
    "      '.000.',\n",
    "      '.....',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '..0..',\n",
    "      '..00.',\n",
    "      '.....']]\n",
    "#O\n",
    "O = [['.....',\n",
    "      '.....',\n",
    "      '.00..',\n",
    "      '.00..',\n",
    "      '.....']]\n",
    "#S\n",
    "S = [['.....',\n",
    "      '..0..',\n",
    "      '..00.',\n",
    "      '...0.',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '.....',\n",
    "      '..00.',\n",
    "      '.00..',\n",
    "      '.....']]\n",
    "#T\n",
    "T = [['.....',\n",
    "      '..0..',\n",
    "      '.000.',\n",
    "      '.....',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '..00.',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '.....',\n",
    "      '.000.',\n",
    "      '..0..',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '.00..',\n",
    "      '..0..',\n",
    "      '.....']]\n",
    "#Z\n",
    "Z = [['.....',\n",
    "      '.....',\n",
    "      '.00..',\n",
    "      '..00.',\n",
    "      '.....'],\n",
    "     ['.....',\n",
    "      '..0..',\n",
    "      '.00..',\n",
    "      '.0...',\n",
    "      '.....']]\n",
    "shapes = [I, J, L, O, S, T, Z]\n",
    "shapes_color = [(255,0,0),(0,255,0),\n",
    "                (0,0,255),(0,255,255),\n",
    "                (255,0,255),(255,255,0),\n",
    "                (128,0,128)]\n",
    "pygame.font.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Piece(object):\n",
    "    def __init__ (self, x, y, shape):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.shape = shape\n",
    "        self.color = shapes_color[shapes.index(shape)]\n",
    "        self.rotation = int(np.random.rand()*len(shape))\n",
    "\n",
    "def create_grid(locked_pos = {}):\n",
    "    grid = [[(0,0,0) for _ in range(blocks_w)] for _ in range(blocks_h)]\n",
    "    for hgt in range(blocks_h):\n",
    "        for wid in range(blocks_w):\n",
    "            if (wid, hgt) in locked_pos:\n",
    "                clr = locked_pos[(wid,hgt)]\n",
    "                grid[hgt][wid] = clr\n",
    "    return grid\n",
    "\n",
    "def convert_shape_fmt(this_shape):\n",
    "    posit = []\n",
    "    fmt = this_shape.shape [this_shape.rotation % len(this_shape.shape)]\n",
    "    for i, line in enumerate(fmt):\n",
    "        row = list(line)\n",
    "        for j, col in enumerate(row):\n",
    "            if col == '0':\n",
    "                posit.append((int(this_shape.x + j), int(this_shape.y + i)))\n",
    "                             \n",
    "    for i, pos in enumerate(posit):\n",
    "        posit[i] = (int(pos[0]-2), int(pos[1]-4))\n",
    "    return posit\n",
    "\n",
    "def valid_space(grid, piece):\n",
    "    accepted_pos = [[(j,i) for j in range (blocks_w) if grid[i][j] == (0,0,0)] for i in range (blocks_h)]\n",
    "    accepted_pos = [j for sub in accepted_pos for j in sub]\n",
    "    formatted = convert_shape_fmt(piece)\n",
    "    for pos in formatted:\n",
    "        if pos not in accepted_pos:\n",
    "            if pos[1] > -1:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def check_lost(positions):\n",
    "    for pos in positions:\n",
    "        x, y = pos\n",
    "        if y < -1:\n",
    "            now = datetime.now()\n",
    "            dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\\n\")\n",
    "            with open('data/score_log','a') as f:\n",
    "                f.writelines(str(int(score))+','+dt_string)\n",
    "#             return score\n",
    "\n",
    "            time_step.is_last = True\n",
    "            return True\n",
    "    time_step.is_last = False\n",
    "    return False\n",
    "\n",
    "def get_shape():\n",
    "    return Piece(start_x, 0, np.random.choice(shapes))\n",
    "\n",
    "def draw_text_middle(surface, text, size, color):\n",
    "    font = pygame.font.SysFont('Arial',size, bold = True)\n",
    "    bolded = font.render(text, 1, color)\n",
    "    surface.blit(bolded,((full_w-bolded.get_width())/2, (full_h-bolded.get_height())/2))\n",
    "\n",
    "def draw_grid(surface, grid):\n",
    "    for hgt in range(blocks_h+1):\n",
    "        pygame.draw.line(surface,(128,128,128), \n",
    "                         (top_left_x, top_left_y + hgt*block_size), \n",
    "                         (top_left_x + blocks_w*block_size, top_left_y + hgt*block_size))\n",
    "    for wid in range(blocks_w+1):\n",
    "        pygame.draw.line(surface,(128,128,128), \n",
    "                         (top_left_x + wid*block_size, top_left_y), \n",
    "                         (top_left_x + wid*block_size, top_left_y + blocks_h*block_size))\n",
    "\n",
    "\n",
    "def clear_rows(grid, locked):\n",
    "\n",
    "    inc = 0\n",
    "    # backward (bottom to top scan)\n",
    "    for i in range(len(grid)-1, -1, -1):\n",
    "        row = grid[i]\n",
    "        if (0, 0, 0) not in row:\n",
    "            inc += 1\n",
    "            for j in range(len(row)):\n",
    "                del locked[(j,i)]\n",
    "        else:\n",
    "            if inc > 0:\n",
    "                k = i+inc\n",
    "                for j in range(len(row)):\n",
    "                    if (j,i) in locked:\n",
    "                        locked[(j,k)] = locked[(j,i)]\n",
    "                        del locked[(j,i)]\n",
    "\n",
    "    return inc, locked\n",
    "\n",
    "def draw_next_shape(surface, shp):\n",
    "    font = pygame.font.SysFont('Arial',60)\n",
    "    next_s = font.render('Next Shape:',1, (255,255,255))\n",
    "    next_x = top_left_x + play_w + 150\n",
    "    next_y = top_left_y + play_h/2 - 150\n",
    "    fmt = shp.shape[shp.rotation]\n",
    "    \n",
    "    for i, line in enumerate(fmt):\n",
    "        row = list(line)\n",
    "        for j,col in enumerate(row):\n",
    "            if col == '0':\n",
    "                pygame.draw.rect(surface, shp.color, (next_x + j*block_size, \n",
    "                                 next_y + i*block_size, \n",
    "                                 block_size, block_size), 0)\n",
    "    surface.blit(next_s, (next_x - 50, next_y - 100))\n",
    "\n",
    "# def add_score(score):\n",
    "#     now = datetime.now()\n",
    "#     dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\\n\")\n",
    "#     with open('data/score_log','a') as f:\n",
    "#         f.writelines(str(int(score))+','+dt_string)\n",
    "#     return score\n",
    "\n",
    "def draw_window(surface, grid, score):\n",
    "    surface.fill((0,0,0))\n",
    "    pygame.font.init()\n",
    "    font = pygame.font.SysFont('Arial',60)\n",
    "    title = font.render('Tetris',1, (255,255,255))\n",
    "    surface.blit(title,(full_w/2 - title.get_width()/2, 20))\n",
    "    \n",
    "    font = pygame.font.SysFont('Arial',60)\n",
    "    score_s = font.render('Score:',1, (255,255,255))\n",
    "    score_x = 50\n",
    "    score_y = top_left_y + 50\n",
    "    surface.blit(score_s, (score_x, score_y))\n",
    "    score_s = font.render(str(score),1, (255,255,255))\n",
    "    score_x = 100\n",
    "    score_y += 100\n",
    "    surface.blit(score_s, (score_x, score_y))\n",
    "    \n",
    "    for hgt in range(blocks_h):\n",
    "        for wid in range(blocks_w):\n",
    "            pygame.draw.rect(surface, grid[hgt][wid],\n",
    "                             (top_left_x + wid*block_size, \n",
    "                            top_left_y + hgt*block_size, \n",
    "                            block_size, block_size), 0)\n",
    "    pygame.draw.rect(surface, (255,0,0), (top_left_x, top_left_y, play_w, play_h), 4)\n",
    "    draw_grid(surface, grid)\n",
    "#     pygame.display.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tetris(py_environment.PyEnvironment):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=4, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(blocks_h,blocks_w), dtype=np.int32, minimum=0, name='observation')\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        self.win = pygame.display.set_mode((full_w, full_h))\n",
    "        pygame.display.set_caption('Tetris')\n",
    "        self.win.fill((0, 0, 0))\n",
    "#         draw_text_middle(win,\"Press any key to Start\", 60, (255, 255, 255))\n",
    "        self.locked_blocks = {}\n",
    "        self.grid = create_grid(self.locked_blocks)\n",
    "\n",
    "        self.change_piece = False\n",
    "#     run = True\n",
    "        self.next_piece = get_shape()\n",
    "        self.curr_piece = get_shape()\n",
    "        self.score = 0\n",
    "        pygame.display.update()\n",
    "    \n",
    "#     clock = pygame.time.Clock()\n",
    "#     fall_time = 0\n",
    "#     fall_speed =.27\n",
    "#     level_time = 0\n",
    "#     score = 0\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self.grid\n",
    "#         return self._observation_spec\n",
    "\n",
    "    def time_step_spec(self):\n",
    "        \"\"\"Return time_step_spec.\"\"\"\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "#     if self._episode_ended:\n",
    "#       # The last action ended the episode. Ignore the current action and start\n",
    "#       # a new episode.\n",
    "#       TETRIS BOARD CLOGGED\n",
    "#       return self.reset()\n",
    "\n",
    "#     # Make sure episodes don't go on forever.     \n",
    "#     TETRIS GAME WILL END\n",
    "#     if action == 1:\n",
    "#       self._episode_ended = True\n",
    "#     elif action == 0:\n",
    "#       new_card = np.random.randint(1, 11)\n",
    "#       self._state += new_card\n",
    "#     else:\n",
    "        if action < 0 or action > 4:\n",
    "            raise ValueError('`action` should be between 0 and 4.')\n",
    "        self.curr_piece.y += 1\n",
    "        self.grid = create_grid(self.locked_blocks)\n",
    "        if not (valid_space(self.grid, self.curr_piece)) and (self.curr_piece.y > 0):\n",
    "            self.curr_piece.y -= 1\n",
    "            self.change_piece = True\n",
    "        \n",
    "        self.grid = create_grid(self.locked_blocks)\n",
    "        key_choice = action #(self.grid, self.curr_piece)\n",
    "        if key_choice == LEFT_KEY:\n",
    "            self.curr_piece.x -= 1\n",
    "            if not (valid_space(self.grid, self.curr_piece)):\n",
    "                self.curr_piece.x += 1\n",
    "        if key_choice == RIGHT_KEY:\n",
    "            self.curr_piece.x += 1\n",
    "            if not (valid_space(self.grid, self.curr_piece)):\n",
    "                self.curr_piece.x -= 1\n",
    "        if key_choice == DOWN_KEY:\n",
    "            while valid_space(self.grid, self.curr_piece):\n",
    "                self.curr_piece.y += 1\n",
    "            self.curr_piece.y -= 1\n",
    "        if key_choice == UP_KEY:\n",
    "            self.curr_piece.rotation += 1 \n",
    "            self.curr_piece.rotation %= len(self.curr_piece.shape)\n",
    "            if not (valid_space(self.grid, self.curr_piece)):\n",
    "                if self.curr_piece.rotation == 0:\n",
    "                    self.curr_piece.rotation = len(self.curr_piece.shape) - 1\n",
    "                else:\n",
    "                    self.curr_piece.rotation -= 1\n",
    "        # if none of the above, piece drops one row\n",
    "\n",
    "        shape_pos = convert_shape_fmt(self.curr_piece)\n",
    "        for i in range(len(shape_pos)):\n",
    "            x, y = shape_pos[i]\n",
    "            if y > -1:\n",
    "                self.grid[y][x] = self.curr_piece.color\n",
    "        if self.change_piece:\n",
    "            for pos in shape_pos:\n",
    "                p = (pos[0],pos[1])\n",
    "                self.locked_blocks[p] = self.curr_piece.color\n",
    "            self.curr_piece = self.next_piece\n",
    "            self.next_piece = get_shape()\n",
    "            self.change_piece = False\n",
    "            increment, new_block_set = clear_rows(self.grid, self.locked_blocks)\n",
    "            self.score += increment * 10\n",
    "            self.locked_blocks = new_block_set\n",
    "\n",
    "        draw_window(self.win, self.grid, self.score)\n",
    "        draw_next_shape(self.win, self.next_piece)\n",
    "        pygame.display.update()\n",
    "\n",
    "        self._state = 1\n",
    "        if check_lost(self.locked_blocks):\n",
    "#             draw_text_middle(win, \"You Lost!\", 80, (255, 255, 255))\n",
    "            self._state = 2\n",
    "            pygame.display.update()\n",
    "#             pygame.time.delay(end_wait)\n",
    "#             run = False\n",
    "#             self.score = add_score(self.score)\n",
    "            self._episode_ended = True\n",
    "        if self._episode_ended:\n",
    "            return ts.termination(np.array([self._state], dtype=np.int32), self.score)\n",
    "        else:\n",
    "            return ts.transition(\n",
    "                np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)\n",
    "#     return win, score, grid, locked_blocks, curr_piece, next_piece, check_lost\n",
    "#     if self._episode_ended or self._state >= 21:\n",
    "#       reward = self._state - 21 if self._state <= 21 else -21\n",
    "#       return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "#     else:\n",
    "#       return ts.transition(\n",
    "#           np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action = np.array(0, dtype=np.int32)  # test with do nothing\n",
    "# time_step = environment.reset()\n",
    "# print(time_step)\n",
    "# while not time_step.is_last():\n",
    "#   time_step = environment.step(action)\n",
    "#   print(time_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "environment = Tetris()\n",
    "# utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was for testing the agent\n",
    "\n",
    "\n",
    "# get_new_card_action = np.array(0, dtype=np.int32)\n",
    "# end_round_action = np.array(2, dtype=np.int32)\n",
    "\n",
    "# environment = Tetris()\n",
    "# time_step = environment.reset()\n",
    "# # print(time_step)\n",
    "# cumulative_reward = time_step.reward\n",
    "\n",
    "# for episode in range (3):\n",
    "#     time_step = environment.reset()\n",
    "#     done = False\n",
    "#     # for _ in range(20):\n",
    "#     while not done:\n",
    "#         time_step = environment.step(get_new_card_action)\n",
    "#         #     print(time_step)\n",
    "#         cumulative_reward += time_step.reward\n",
    "#         if time_step.step_type == 2:\n",
    "#             print(time_step)\n",
    "#             done = True\n",
    "#             time_step = environment.step(end_round_action)\n",
    "            \n",
    "#             now = datetime.now()\n",
    "#             dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\\n\")\n",
    "#             with open('data/score_log','a') as f:\n",
    "#                 f.writelines(str(episode+1)+','+str(int(time_step.reward))+','+dt_string)\n",
    "# #         return score\n",
    "\n",
    "\n",
    "# #comment out the following line to display last result\n",
    "# pygame.display.quit()\n",
    "\n",
    "# # print(time_step)\n",
    "# cumulative_reward += time_step.reward\n",
    "# print('Final Reward = ', cumulative_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.display.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No known conversion from type `<class 'NoneType'>` to a TensorSpec\n  In call to configurable 'TFPyEnvironment' (<class 'tf_agents.environments.tf_py_environment.TFPyEnvironment'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-db31d5917840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_py_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFPyEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTetris\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfc_layer_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" in scope '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m       \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gin/utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tf_agents/environments/tf_py_environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, environment, check_dims, isolation)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0maction_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mtime_step_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tf_agents/specs/tensor_spec.py\u001b[0m in \u001b[0;36mfrom_spec\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m     67\u001b[0m                        type(s))\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_to_tensor_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tf_agents/specs/tensor_spec.py\u001b[0m in \u001b[0;36m_convert_to_tensor_spec\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       raise ValueError(\"No known conversion from type `%s` to a TensorSpec\" %\n\u001b[0;32m---> 67\u001b[0;31m                        type(s))\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_to_tensor_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No known conversion from type `<class 'NoneType'>` to a TensorSpec\n  In call to configurable 'TFPyEnvironment' (<class 'tf_agents.environments.tf_py_environment.TFPyEnvironment'>)"
     ]
    }
   ],
   "source": [
    "# train_env = tf_py_environment.TFPyEnvironment(Tetris)\n",
    "\n",
    "\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "q_net = q_network.QNetwork(\n",
    "    Tetris.observation_spec(),\n",
    "    Tetris.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "time_step_spec() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3600f07c412a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m agent = dqn_agent.DqnAgent(\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mTetris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mTetris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mq_network\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: time_step_spec() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    Tetris.time_step_spec(),\n",
    "    Tetris.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f9f297550b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcollect_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c91e5e61db2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                 train_env.action_spec())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_env' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-debb1fd9e913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTetris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrandom_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'random_policy' is not defined"
     ]
    }
   ],
   "source": [
    "environment = Tetris()\n",
    "random_policy = random_tf_policy.RandomTFPolicy(environment.time_step_spec(),\n",
    "                                                environment.action_spec())\n",
    "time_step = environment.reset()\n",
    "random_policy.action(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "        \n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "        \n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3b7f8579967a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_avg_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_eval_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_env' is not defined"
     ]
    }
   ],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.collect_data_spec._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "    # Add trajectory to the replay buffer\n",
    "    buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "    for _ in range(steps):\n",
    "        collect_step(env, policy, buffer)\n",
    "\n",
    "collect_data(train_env, random_policy, replay_buffer, steps=100)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations. \n",
    "# For more details see the drivers module.\n",
    "# https://www.tensorflow.org/agents/api_docs/python/tf_agents/drivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %%time\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "    for _ in range(collect_steps_per_iteration):\n",
    "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.display.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
